{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBWmB-5uSd4L",
    "outputId": "fdecacbb-ef94-4c28-e399-5da3051fea97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Study\\sem8\\dataset\\dataset_bhargavi\\megatron\n"
     ]
    }
   ],
   "source": [
    "cd D:/Study/sem8/dataset/dataset_bhargavi/megatron/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R4BmKxbspGN9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'export' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!export MYDIR=$D:/Study/sem8/dataset/dataset_bhargavi/megatron/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0L0AN0DStHc",
    "outputId": "f0adc4a2-2042-4822-9cdd-182b30bd6d00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Path to the input CSV file\n",
    "input_file_path = 'data.csv'\n",
    "\n",
    "# Path to the output CSV file for the first 100k lines\n",
    "output_file_path = 'data_small.csv'\n",
    "\n",
    "# Number of lines to read\n",
    "num_lines = 100000\n",
    "\n",
    "# Open the input CSV file in read mode\n",
    "with open(input_file_path, 'r', newline='') as input_file:\n",
    "    # Open the output CSV file in write mode\n",
    "    with open(output_file_path, 'w', newline='') as output_file:\n",
    "        # Create CSV reader and writer objects\n",
    "        csv_reader = csv.reader(input_file)\n",
    "        csv_writer = csv.writer(output_file)\n",
    "\n",
    "        # Write the first 100k lines to the output file\n",
    "        for line_num, line in enumerate(csv_reader):\n",
    "            csv_writer.writerow(line)\n",
    "            if line_num + 1 >= num_lines:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ph7_TjHcpzWb"
   },
   "outputs": [],
   "source": [
    "!mkdir -p $MYDIR/nvidia/megatron-bert-uncased-345m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gzr8fR9FTSoG",
    "outputId": "b89738a0-3eca-4975-fff0-6d43339ef1b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under D:/Study/sem8/dataset/dataset_bhargavi/megatron/nvidia/megatron-bert-uncased-345m/checkpoint.zip\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://api.ngc.nvidia.com/v2/models/nvidia/megatron_bert_345m/versions/v0.1_uncased/zip -o D:/Study/sem8/dataset/dataset_bhargavi/megatron/nvidia/megatron-bert-uncased-345m/checkpoint.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: boto3 in d:\\anaconda\\lib\\site-packages (from transformers) (1.24.28)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex in d:\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Collecting sentencepiece (from transformers)\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/a2/f6/587c62fd21fc988555b85351f50bbde43a51524caafd63bc69240ded14fd/sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: sacremoses in d:\\anaconda\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in d:\\anaconda\\lib\\site-packages (from boto3->transformers) (1.27.59)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in d:\\anaconda\\lib\\site-packages (from boto3->transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in d:\\anaconda\\lib\\site-packages (from boto3->transformers) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from sacremoses->transformers) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in d:\\anaconda\\lib\\site-packages (from botocore<1.28.0,>=1.27.28->boto3->transformers) (2.8.2)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   - ------------------------------------- 41.0/991.5 kB 960.0 kB/s eta 0:00:01\n",
      "   ------- -------------------------------- 194.6/991.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 409.6/991.5 kB 3.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 675.8/991.5 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 849.9/991.5 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  983.0/991.5 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzQs8Au7TcGk",
    "outputId": "3f23ed10-d0dd-4fc8-e1e7-35379282ef72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 22:44:57.813514: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-26 22:44:59.670873: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-26 22:45:14.788841: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Study\\sem8\\dataset\\dataset_bhargavi\\megatron\\transformers-main\\transformers-main\\src\\transformers\\models\\megatron_bert\\convert_megatron_bert_checkpoint.py\", line 42, in <module>\n",
      "    from transformers import MegatronBertConfig\n",
      "ImportError: cannot import name 'MegatronBertConfig' from 'transformers' (D:\\Anaconda\\Lib\\site-packages\\transformers\\__init__.py)\n"
     ]
    }
   ],
   "source": [
    "!python D:/Study/sem8/dataset/dataset_bhargavi/megatron/transformers-main/transformers-main/src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py D:/Study/sem8/dataset/dataset_bhargavi/megatron/nvidia/megatron-bert-uncased-345m/checkpoint.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9Jdd_fUTfAA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, MegatronBertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ruMdASYUuCr"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "class LogDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length,mode=\"Train\"):\n",
    "        self.mode = mode\n",
    "        self.texts = data['logs'].tolist()\n",
    "        if self.mode!=\"Test\":\n",
    "            self.labels = data['Label'].astype('category').cat.codes.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        if self.mode!=\"Test\":\n",
    "            label = self.labels[index]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        if self.mode!=\"Test\":\n",
    "            return {\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'labels': torch.tensor(label)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "_rkgYBzkVodL",
    "outputId": "4b88a097-48cb-4b94-e397-d91781ea6264"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>merged_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2008-11-09 8:35:18 PM 143 blk_-160899968791986...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2008-11-09 8:35:18 PM 35 blk_-1608999687919862...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2008-11-09 8:35:19 PM 143 blk_-160899968791986...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2008-11-09 8:35:19 PM 145 blk_-160899968791986...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2008-11-09 8:35:19 PM 145 blk_-160899968791986...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2008-11-09 8:49:01 PM 645 blk_3844474760914334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2008-11-09 8:49:01 PM 646 blk_4250700552550942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2008-11-09 8:49:01 PM 648 blk_5892345988522203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2008-11-09 8:49:01 PM 648 blk_5892345988522203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Anomaly</td>\n",
       "      <td>2008-11-09 8:49:01 PM 649 blk_8586954888883584...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99999 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Response                                    merged_features\n",
       "0       Normal  2008-11-09 8:35:18 PM 143 blk_-160899968791986...\n",
       "1       Normal  2008-11-09 8:35:18 PM 35 blk_-1608999687919862...\n",
       "2       Normal  2008-11-09 8:35:19 PM 143 blk_-160899968791986...\n",
       "3       Normal  2008-11-09 8:35:19 PM 145 blk_-160899968791986...\n",
       "4       Normal  2008-11-09 8:35:19 PM 145 blk_-160899968791986...\n",
       "...        ...                                                ...\n",
       "99994   Normal  2008-11-09 8:49:01 PM 645 blk_3844474760914334...\n",
       "99995   Normal  2008-11-09 8:49:01 PM 646 blk_4250700552550942...\n",
       "99996   Normal  2008-11-09 8:49:01 PM 648 blk_5892345988522203...\n",
       "99997   Normal  2008-11-09 8:49:01 PM 648 blk_5892345988522203...\n",
       "99998  Anomaly  2008-11-09 8:49:01 PM 649 blk_8586954888883584...\n",
       "\n",
       "[99999 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_small.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSTH6QHSVlxk"
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0AMCxkkWspp",
    "outputId": "9e66e3d5-4888-4e5b-cc9b-97c594a47bff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MegatronBertForSequenceClassification were not initialized from the model checkpoint at /nvidia/megatron-bert-uncased-345m and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MegatronBertForSequenceClassification(\n",
       "  (bert): MegatronBertModel(\n",
       "    (embeddings): MegatronBertEmbeddings(\n",
       "      (word_embeddings): Embedding(30592, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): MegatronBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x MegatronBertLayer(\n",
       "          (attention): MegatronBertAttention(\n",
       "            (ln): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self): MegatronBertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): MegatronBertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ln): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (intermediate): MegatronBertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): MegatronBertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (pooler): MegatronBertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('nvidia/megatron-bert-uncased-345m')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "directory = os.path.join('/', 'nvidia/megatron-bert-uncased-345m')\n",
    "\n",
    "model = MegatronBertForSequenceClassification.from_pretrained(directory, num_labels=3)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2EdARiSXXPF"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unURYTUKW9bf"
   },
   "outputs": [],
   "source": [
    "train_dataset = LogDataset(train_data, tokenizer, max_length)\n",
    "val_dataset = LogDataset(val_data, tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ng8zOrxwXZso",
    "outputId": "0684ad38-0be9-455e-80aa-16b089ea34dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  5511, 14526,  ...,     0,     0,     0],\n",
      "        [  101,  5511, 14526,  ...,     0,     0,     0],\n",
      "        [  101,  5511, 14526,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  5511, 14526,  ...,     0,     0,     0],\n",
      "        [  101,  5511, 14526,  ...,     0,     0,     0],\n",
      "        [  101,  5511, 14526,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ks98Ytzsq9ZH",
    "outputId": "8fb2ff1c-bd17-4daa-dcfe-ff80023cc6d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28293, 7074)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader),len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "uRnRK-hrrAIm",
    "outputId": "907d88fe-c5f4-463a-9bd4-a7af6a82627c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-3d1fba964cf4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{epochs}', leave=False)\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': total_loss / len(train_dataloader)})\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}: Train Loss = {total_loss / len(train_dataloader)}, Val Loss = {val_loss / len(val_dataloader)}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
